'''
SAMPLE KNN USING TITANIC DATA FROM KAGGLE:
Suvived is the Y variable being analyzed for this project.
'''
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

#Import the data set
tDF = pd.read_csv(r'C:\Users\Scott\Desktop\titanic_train.csv')

#Drop all rows with missing data:
tDF.dropna(inplace=True)
#print(titanic_data)

#These values have no numeric value:
tDF.drop(['Name', 'PassengerId', 'Ticket', 'Sex', 'Embarked', 'Cabin'], axis = 1, inplace = True)



#Import standardization functions from scikit-learn
from sklearn.preprocessing import StandardScaler

#Standardize the data set
scaler = StandardScaler()
scaler.fit(tDF.drop('Survived', axis=1))
scaled_features = scaler.transform(tDF.drop('Survived', axis=1))
scaled_data = pd.DataFrame(scaled_features, columns = tDF.drop('Survived', axis=1).columns)

#Split the data set into training data and test data
from sklearn.model_selection import train_test_split
x = scaled_data
y = tDF['Survived']
x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x, y, test_size = 0.3)

#Train the model and make predictions
from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors = 1)
model.fit(x_training_data, y_training_data)
predictions = model.predict(x_test_data)

#Performance measurement
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
print(classification_report(y_test_data, predictions))
print(confusion_matrix(y_test_data, predictions))

#Selecting an optimal K value
error_rates = []
for i in np.arange(1, 101):
    new_model = KNeighborsClassifier(n_neighbors = i)
    new_model.fit(x_training_data, y_training_data)
    new_predictions = new_model.predict(x_test_data)
    error_rates.append(np.mean(new_predictions != y_test_data))

plt.figure(figsize=(16,12))
plt.plot(error_rates)

'''
      precision    recall  f1-score   support

           0       0.37      0.41      0.39        17
           1       0.72      0.68      0.70        38

    accuracy                           0.60        55
   macro avg       0.55      0.55      0.55        55
weighted avg       0.61      0.60      0.61        55

[[ 7 10]
 [12 26]]

'''
